apiVersion: elastic.pytorch.org/v1alpha1
kind: ElasticJob
metadata:
  name: huggingface-oscar
  #namespace: elastic-job
spec:
  # Use "etcd-service:2379" if you already apply etcd.yaml
  rdzvEndpoint: etcd-service:2379
  minReplicas: 1
  maxReplicas: 128
  replicaSpecs:
    Worker:
      replicas: 3
      restartPolicy: ExitCode
      template:
        apiVersion: v1
        kind: Pod
        spec:
          nodeSelector:
            beta.kubernetes.io/instance-type: p3.8xlarge
          containers:
            - name: elasticjob-worker
              image: 999701187340.dkr.ecr.us-west-2.amazonaws.com/torchelastic-huggingface
              imagePullPolicy: Always
              env:
                - name: NCCL_DEBUG
                  value: INFO
              #  - name: NCCL_SOCKET_IFNAME
              #    value: lo
              #  - name: FI_PROVIDER
              #    value: sockets
              args:
                - "--nproc_per_node=4"
                - "/workspace/examples/huggingface/main.py"
                - "--epochs=20"
                - "--batch-size=8"
                # number of data loader workers (NOT trainers)
                # zero means load the data on the same process as the trainer
                # this is set so that the container does not OOM since
                # pytorch data loaders use shm
                - "--workers=8"
                - "--checkpoint-file=/shared-efs/arxiv/checkpoint.pth.tar"
                - "/shared-efs/arxiv/text"
                - "--learning_rate=0.000035"
                - "--optimizer=AdamW"
              resources:
                limits:
                  nvidia.com/gpu: 4
              volumeMounts:
                - name: efs-pvc
                  mountPath: /shared-efs
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: efs-pvc
              persistentVolumeClaim:
                claimName: efs-claim
            - name: dshm
              emptyDir:     
                medium: Memory
